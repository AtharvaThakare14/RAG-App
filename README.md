# End-to-End RAG Application with Evaluation on AWS

Terraform-based **Infrastructure as Code (IaC)** to deploy a complete AWS backend for a Retrieval-Augmented Generation (RAG) application. It integrates with Googleâ€™s free-tier Gemini Pro and Embedding models for AI-powered document querying and includes a Streamlit UI with token-based authentication for interacting with the app.

ğŸ’° **Estimated cost**: ~$3 (~â‚¹250) to experiment without the AWS Free Tier, primarily for RDS and NAT Gateway if active.

ğŸ‘‰ **Related UI**: [RAG UI (Streamlit Frontend)](https://github.com/genieincodebottle/rag-app-on-aws/tree/main/rag_ui) â€” A Streamlit-based frontend application designed to interact with the backend infrastructure deployed by this project.

---

## ğŸ” Overview

This repository contains the complete Terraform codebase for provisioning and managing the AWS infrastructure that powers a RAG application. It allows users to upload documents, which are processed, embedded, and stored for efficient semantic search and AI-driven querying.

**Key features include:**
- **IaC with Terraform** for consistent deployments.
- **Serverless Compute** using AWS Lambda for backend logic.
- **Vector Storage** with PostgreSQL RDS and `pgvector`.
- **AI Integration** with Googleâ€™s Gemini Pro and Embedding models.
- **Authentication** via AWS Cognito.
- **CI/CD Workflows** using GitHub Actions.
- **Multi-Environment Support** (`dev`, `staging`, `production`).
- **Comprehensive Testing** for backend Lambdas.
- **Streamlit UI** for document upload, querying, and evaluation.

---

## ğŸŒ Network Flow Walkthrough

**Document Processing Flow**
1. User uploads document â†’ API Gateway â†’ `upload_handler` Lambda.
2. Lambda stores file in S3.
3. S3 triggers `document_processor` Lambda.
4. Processor generates embeddings using Gemini API.
5. Stores embeddings and metadata in PostgreSQL RDS.

**Query Processing Flow**
1. User query â†’ API Gateway â†’ `query_processor` Lambda.
2. Lambda performs vector similarity search in PostgreSQL.
3. Retrieves relevant chunks and context.
4. Uses Gemini Pro to generate answer.
5. Returns result to user.

---

## ğŸ—‚ Repository Structure
```
.
â”œâ”€â”€ .github/workflows/       # CI/CD via GitHub Actions
â”‚   â”œâ”€â”€ deploy.yml           # Infrastructure deployment workflow
â”‚   â””â”€â”€ manual_cleanup.yml   # Resource cleanup workflow
â”œâ”€â”€ environments/            # Environment-specific configs (dev, staging, prod)
â”‚   â””â”€â”€ dev/                 # Example 'dev' environment
â”‚       â”œâ”€â”€ main.tf          # Root Terraform file for the environment
â”‚       â”œâ”€â”€ providers.tf     # Terraform provider configurations
â”‚       â””â”€â”€ variables.tf     # Environment-specific variable definitions
â”œâ”€â”€ modules/                 # Reusable Terraform modules
â”‚   â”œâ”€â”€ api/                 # API Gateway configuration
â”‚   â”œâ”€â”€ auth/                # Cognito authentication
â”‚   â”œâ”€â”€ compute/             # Lambda functions & IAM roles
â”‚   â”œâ”€â”€ database/            # PostgreSQL RDS with pgvector & Secrets Manager
â”‚   â”œâ”€â”€ monitoring/          # CloudWatch Logs, Alarms & SNS Topic
â”‚   â”œâ”€â”€ storage/             # S3 Buckets & DynamoDB Table
â”‚   â””â”€â”€ vpc/                 # VPC, Subnets, NAT, Security Groups, Endpoints
â”œâ”€â”€ rag_ui/                  # Streamlit UI application
â”‚   â”œâ”€â”€ app.py               # Main Streamlit application code
â”‚   â””â”€â”€ README.md            # README specific to the UI
â”œâ”€â”€ scripts/                 # Utility shell scripts
â”‚   â”œâ”€â”€ cleanup.sh           # Comprehensive resource cleanup script
â”‚   â”œâ”€â”€ import_resources.sh  # Script to import existing AWS resources into Terraform state
â”‚   â””â”€â”€ network-diagnostics.sh # Script for troubleshooting network connectivity (e.g., Lambda to RDS)
â”œâ”€â”€ src/                     # Lambda backend source code (Python)
â”‚   â”œâ”€â”€ auth_handler/        # Lambda for Cognito authentication operations
â”‚   â”œâ”€â”€ db_init/             # Lambda for database schema and pgvector initialization
â”‚   â”œâ”€â”€ document_processor/  # Lambda for processing uploaded documents
â”‚   â”œâ”€â”€ query_processor/     # Lambda for handling user queries and RAG
â”‚   â”œâ”€â”€ tests/               # Unit and integration tests
â”‚   â”‚   â”œâ”€â”€ integration/     # Integration tests for deployed services
â”‚   â”‚   â”‚   â””â”€â”€ run_integration_tests.py
â”‚   â”‚   â”œâ”€â”€ unit/            # Unit tests for Lambda functions
â”‚   â”‚   â”‚   â”œâ”€â”€ conftest.py  # Pytest common fixtures and mocks
â”‚   â”‚   â”‚   â”œâ”€â”€ test_*.py    # Individual unit test files
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ upload_handler/      # Lambda for handling file uploads via API
â”‚   â””â”€â”€ utils/               # Shared utility code (e.g., db_connectivity_test.py)
â”œâ”€â”€ sonar-project.properties # SonarQube configuration file
â””â”€â”€ tox.ini                  # tox configuration for running tests and linters

---

## ğŸ§± Infrastructure Components

**1. Networking (VPC)**
- Custom VPC with public, private, and DB subnets.
- NAT & Internet Gateways.
- Security Groups and VPC Endpoints.
- Optional VPC Flow Logs.

**2. Compute (Lambda Functions)**
- Authentication (`auth_handler`).
- Document Processing (`document_processor`).
- Query Handling (`query_processor`).
- File Upload (`upload_handler`).
- Database Initialization (`db_init`).

**3. Storage**
- S3 Buckets for documents, Lambda packages, and Terraform state.
- DynamoDB for document metadata and Terraform locks.
- PostgreSQL RDS with `pgvector`.

**4. API & Authentication**
- API Gateway routes: `/upload`, `/query`, `/auth`.
- Cognito for user management.
- JWT-based API Authorization.
- AWS Secrets Manager for credentials.

**5. Monitoring & Alerts**
- CloudWatch Logs & Alarms.
- SNS notifications for alerts.

---

## âš™ï¸ Build and Deployment

**Prerequisites**
- Python 3.11+
- AWS Account
- GitHub Account
- Git installed locally
- Google API Key for Gemini models
- (Optional) SonarCloud account for code quality checks

**Deployment Steps**
1. Fork this repo.
2. Clone locally.
3. Update `terraform.tfvars` for your environment.
4. Add required GitHub Secrets:
   - `AWS_ACCESS_KEY_ID`
   - `AWS_SECRET_ACCESS_KEY`
   - (Optional) `SONAR_TOKEN`
5. Trigger GitHub Actions pipeline to deploy.

---

## ğŸŒ Environment Management
Supports multiple environments (`dev`, `staging`, `prod`) with separate configurations in `environments/`.

---

## ğŸš€ Running the Streamlit UI
1. Deploy AWS resources.
2. Navigate to `rag_ui/`.
3. Create a Python virtual environment and install dependencies.
4. Configure `.env` file with API endpoint and Cognito client ID.
5. Run `streamlit run app.py` and access UI locally.

---

## ğŸ§° Utilities
- `cleanup.sh` â€” remove all AWS resources for an environment.
- `import_resources.sh` â€” import existing resources into Terraform.
- `network-diagnostics.sh` â€” troubleshoot VPC and DB connectivity.

---

## ğŸ§¹ Uninstallation
Use GitHub Actions **Manual AWS Cleanup** workflow or run `cleanup.sh` to remove all resources for a specific environment.
